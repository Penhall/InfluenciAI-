# Guia de ImplementaÃ§Ã£o PrÃ¡tica - Sistema Multi-Agente para InfluenciAI

## 1. FRAMEWORKS E FERRAMENTAS RECOMENDADAS

### 1.1 Plataformas de OrquestraÃ§Ã£o de Agentes

#### AutoGen (Microsoft)
**Melhor para:** ConversaÃ§Ã£o entre mÃºltiplos agentes
```python
# Exemplo de configuraÃ§Ã£o com AutoGen
import autogen

config_list = [
    {
        'model': 'gpt-4-turbo',
        'api_key': 'your-key',
    }
]

# Criar agentes especializados
architect_agent = autogen.AssistantAgent(
    name="SystemArchitect",
    system_message="""You are a Senior System Architect for InfluenciAI.
    Design scalable microservices architecture using .NET 8, Azure, and PostgreSQL.
    Focus on: Clean Architecture, CQRS, Event Sourcing, Domain-Driven Design.""",
    llm_config={"config_list": config_list}
)

backend_agent = autogen.AssistantAgent(
    name="BackendDeveloper",
    system_message="""You are a Senior .NET Developer.
    Implement APIs, business logic, and data access layers.
    Use C# 12, Entity Framework Core, MediatR, and follow SOLID principles.""",
    llm_config={"config_list": config_list}
)

qa_agent = autogen.AssistantAgent(
    name="QAEngineer", 
    system_message="""You are a QA Automation Engineer.
    Write comprehensive tests using xUnit, SpecFlow, and Selenium.
    Ensure >80% code coverage and performance <100ms.""",
    llm_config={"config_list": config_list}
)

# Criar grupo de chat
groupchat = autogen.GroupChat(
    agents=[architect_agent, backend_agent, qa_agent],
    messages=[],
    max_round=20
)

manager = autogen.GroupChatManager(groupchat=groupchat)
```

#### CrewAI
**Melhor para:** Tarefas sequenciais e hierÃ¡rquicas
```python
from crewai import Agent, Task, Crew

# Definir agentes
architect = Agent(
    role='System Architect',
    goal='Design scalable architecture for InfluenciAI',
    backstory='20+ years designing enterprise systems',
    verbose=True,
    allow_delegation=True
)

developer = Agent(
    role='Backend Developer',
    goal='Implement robust APIs and services',
    backstory='Expert in .NET and microservices',
    verbose=True,
    allow_delegation=False
)

# Definir tarefas
design_task = Task(
    description='Design the social media integration architecture',
    agent=architect
)

implement_task = Task(
    description='Implement Twitter API integration service',
    agent=developer
)

# Criar crew
crew = Crew(
    agents=[architect, developer],
    tasks=[design_task, implement_task],
    verbose=True
)

result = crew.kickoff()
```

#### LangGraph
**Melhor para:** Workflows complexos com estado
```python
from langgraph.graph import StateGraph
from typing import TypedDict, List

class ProjectState(TypedDict):
    requirements: str
    architecture: str
    code: str
    tests: str
    documentation: str

def architect_node(state: ProjectState) -> ProjectState:
    # Architect agent logic
    architecture = architect_llm.invoke(state["requirements"])
    return {"architecture": architecture}

def developer_node(state: ProjectState) -> ProjectState:
    # Developer agent logic
    code = developer_llm.invoke(state["architecture"])
    return {"code": code}

def qa_node(state: ProjectState) -> ProjectState:
    # QA agent logic
    tests = qa_llm.invoke(state["code"])
    return {"tests": tests}

# Build graph
workflow = StateGraph(ProjectState)
workflow.add_node("architect", architect_node)
workflow.add_node("developer", developer_node)
workflow.add_node("qa", qa_node)

workflow.add_edge("architect", "developer")
workflow.add_edge("developer", "qa")
workflow.set_entry_point("architect")
workflow.set_finish_point("qa")

app = workflow.compile()
```

### 1.2 Ferramentas de Desenvolvimento com IA

#### GitHub Copilot Workspace
**ConfiguraÃ§Ã£o para InfluenciAI:**
```yaml
# .github/copilot-workspace.yml
name: InfluenciAI Development
context:
  project: Social Media Automation Platform
  stack: 
    - .NET 8
    - Azure
    - PostgreSQL
    - WPF
  patterns:
    - Clean Architecture
    - CQRS
    - Repository Pattern
  
agents:
  - name: backend-specialist
    focus: API development, Entity Framework, MediatR
  - name: frontend-specialist  
    focus: WPF, MVVM, Data Binding
  - name: integration-specialist
    focus: Social media APIs, OAuth, Rate limiting
```

#### Cursor IDE com Claude/GPT-4
**Setup para desenvolvimento agentivo:**
```json
{
  "cursor.aiProvider": "claude-3-opus",
  "cursor.agents": {
    "architect": {
      "prompt": "You are a system architect for InfluenciAI...",
      "temperature": 0.7
    },
    "coder": {
      "prompt": "You are a senior .NET developer...",
      "temperature": 0.3
    }
  },
  "cursor.codeGeneration": {
    "language": "csharp",
    "framework": "dotnet8",
    "testFramework": "xunit"
  }
}
```

#### Devin / OpenDevin
**Para desenvolvimento autÃ´nomo completo:**
```python
# Configuration for Devin-like agent
devin_config = {
    "project": "InfluenciAI",
    "capabilities": [
        "write_code",
        "run_tests",
        "fix_bugs",
        "refactor",
        "deploy"
    ],
    "constraints": {
        "language": "C#",
        "framework": ".NET 8",
        "architecture": "microservices",
        "testing": "minimum 80% coverage"
    }
}
```

### 1.3 Infraestrutura para Agentes

#### Azure AI Agent Service
```bicep
// Azure Bicep template for agent infrastructure
resource agentService 'Microsoft.AgentService/agents@2024-01-01' = {
  name: 'influenciai-agent-service'
  location: 'eastus'
  properties: {
    agentConfigurations: [
      {
        name: 'orchestrator'
        type: 'coordinator'
        model: 'gpt-4-turbo'
        scaling: {
          min: 1
          max: 1
        }
      }
      {
        name: 'developer-pool'
        type: 'worker'
        model: 'gpt-4'
        scaling: {
          min: 2
          max: 10
        }
      }
    ]
  }
}
```

## 2. IMPLEMENTAÃ‡ÃƒO PRÃTICA DO SISTEMA

### 2.1 Estrutura do Projeto de Agentes

```
InfluenciAI-Agents/
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ orchestrator.py
â”‚   â”œâ”€â”€ task_manager.py
â”‚   â””â”€â”€ priority_queue.py
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ base_agent.py
â”‚   â”œâ”€â”€ architect_agent.py
â”‚   â”œâ”€â”€ backend_agent.py
â”‚   â”œâ”€â”€ frontend_agent.py
â”‚   â”œâ”€â”€ qa_agent.py
â”‚   â””â”€â”€ devops_agent.py
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_prompts.yaml
â”‚   â”œâ”€â”€ task_templates.yaml
â”‚   â””â”€â”€ code_patterns.yaml
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ code_generator.py
â”‚   â”œâ”€â”€ test_generator.py
â”‚   â”œâ”€â”€ documentation.py
â”‚   â””â”€â”€ deployment.py
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ knowledge_base.py
â”‚   â””â”€â”€ context_manager.py
â””â”€â”€ evaluation/
    â”œâ”€â”€ code_quality.py
    â”œâ”€â”€ test_coverage.py
    â””â”€â”€ performance.py
```

### 2.2 Base Agent Implementation

```python
# base_agent.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import asyncio
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationSummaryMemory
from langchain.tools import Tool

class BaseAgent(ABC):
    def __init__(self, name: str, role: str, model: str = "gpt-4"):
        self.name = name
        self.role = role
        self.llm = ChatOpenAI(model=model, temperature=0.7)
        self.memory = ConversationSummaryMemory(llm=self.llm)
        self.tools = self._setup_tools()
        self.context = {}
        
    @abstractmethod
    def _setup_tools(self) -> List[Tool]:
        """Define agent-specific tools"""
        pass
    
    @abstractmethod
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Process a specific task"""
        pass
    
    async def collaborate(self, other_agent: 'BaseAgent', message: str) -> str:
        """Collaborate with another agent"""
        response = await other_agent.receive_message(self.name, message)
        self.memory.save_context(
            {"sender": self.name, "message": message},
            {"sender": other_agent.name, "message": response}
        )
        return response
    
    async def receive_message(self, sender: str, message: str) -> str:
        """Receive and process message from another agent"""
        prompt = f"""
        As {self.role}, you received this message from {sender}:
        {message}
        
        Current context: {self.context}
        
        Provide your expert response:
        """
        response = await self.llm.ainvoke(prompt)
        return response.content

# backend_agent.py
class BackendAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="BackendDeveloper",
            role="Senior .NET Developer",
            model="gpt-4"
        )
        
    def _setup_tools(self) -> List[Tool]:
        return [
            Tool(
                name="generate_api",
                func=self._generate_api,
                description="Generate ASP.NET Core API"
            ),
            Tool(
                name="generate_entity",
                func=self._generate_entity,
                description="Generate Entity Framework entity"
            ),
            Tool(
                name="generate_service",
                func=self._generate_service,
                description="Generate business service"
            )
        ]
    
    def _generate_api(self, specification: str) -> str:
        prompt = f"""
        Generate ASP.NET Core 8 API controller based on:
        {specification}
        
        Requirements:
        - Use MediatR for CQRS
        - Include validation
        - Add Swagger documentation
        - Implement error handling
        - Follow REST best practices
        """
        return self.llm.invoke(prompt).content
    
    async def process_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        task_type = task.get("type")
        
        if task_type == "create_api":
            code = self._generate_api(task["specification"])
            tests = await self._generate_tests(code)
            
            return {
                "status": "completed",
                "artifacts": {
                    "api_code": code,
                    "test_code": tests
                }
            }
        
        return {"status": "unsupported_task"}
```

### 2.3 Orchestrator Implementation

```python
# orchestrator.py
import asyncio
from typing import List, Dict, Any
from agents import (
    ArchitectAgent, BackendAgent, FrontendAgent,
    QAAgent, DevOpsAgent, DataAgent
)

class OrchestratorAgent:
    def __init__(self):
        self.agents = {
            "architect": ArchitectAgent(),
            "backend": BackendAgent(),
            "frontend": FrontendAgent(),
            "qa": QAAgent(),
            "devops": DevOpsAgent(),
            "data": DataAgent()
        }
        self.task_queue = asyncio.Queue()
        self.results = {}
        
    async def process_user_story(self, user_story: Dict[str, Any]):
        """Process complete user story through all agents"""
        
        # 1. Architecture Design
        arch_task = {
            "type": "design_architecture",
            "story": user_story
        }
        architecture = await self.agents["architect"].process_task(arch_task)
        
        # 2. Parallel Development
        backend_task = {
            "type": "implement_backend",
            "architecture": architecture,
            "requirements": user_story["acceptance_criteria"]
        }
        
        frontend_task = {
            "type": "implement_frontend",
            "architecture": architecture,
            "requirements": user_story["ui_requirements"]
        }
        
        # Execute in parallel
        backend_result, frontend_result = await asyncio.gather(
            self.agents["backend"].process_task(backend_task),
            self.agents["frontend"].process_task(frontend_task)
        )
        
        # 3. Integration Testing
        qa_task = {
            "type": "integration_test",
            "backend": backend_result,
            "frontend": frontend_result
        }
        test_result = await self.agents["qa"].process_task(qa_task)
        
        # 4. Deployment Preparation
        if test_result["status"] == "passed":
            deploy_task = {
                "type": "prepare_deployment",
                "artifacts": {
                    **backend_result["artifacts"],
                    **frontend_result["artifacts"]
                }
            }
            deployment = await self.agents["devops"].process_task(deploy_task)
            
            return {
                "status": "completed",
                "story_id": user_story["id"],
                "artifacts": deployment["artifacts"]
            }
        
        return {
            "status": "failed",
            "story_id": user_story["id"],
            "errors": test_result["errors"]
        }
    
    async def run_sprint(self, sprint_backlog: List[Dict[str, Any]]):
        """Run complete sprint with all stories"""
        
        results = []
        for story in sprint_backlog:
            print(f"Processing story: {story['title']}")
            result = await self.process_user_story(story)
            results.append(result)
            
            # Daily standup simulation
            await self.daily_standup(story, result)
        
        # Sprint review
        await self.sprint_review(results)
        
        return results
    
    async def daily_standup(self, story: Dict, result: Dict):
        """Simulate daily standup meeting"""
        standup_report = f"""
        ðŸ“… Daily Standup Report
        Story: {story['title']}
        Status: {result['status']}
        Blockers: {result.get('errors', 'None')}
        Next: {self._get_next_action(result)}
        """
        print(standup_report)
        
        # Log to project management tool
        await self.log_to_azure_devops(standup_report)
```

### 2.4 Memory and Context Management

```python
# memory/vector_store.py
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

class ProjectMemory:
    def __init__(self):
        self.embeddings = OpenAIEmbeddings()
        self.vector_store = Chroma(
            persist_directory="./project_memory",
            embedding_function=self.embeddings
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
    
    def store_artifact(self, artifact_type: str, content: str, metadata: Dict):
        """Store project artifact in memory"""
        documents = self.text_splitter.split_text(content)
        
        for i, doc in enumerate(documents):
            self.vector_store.add_texts(
                texts=[doc],
                metadatas=[{
                    **metadata,
                    "type": artifact_type,
                    "chunk": i
                }]
            )
    
    def retrieve_similar(self, query: str, k: int = 5) -> List[str]:
        """Retrieve similar artifacts"""
        results = self.vector_store.similarity_search(query, k=k)
        return [doc.page_content for doc in results]
    
    def get_context_for_task(self, task: Dict) -> str:
        """Get relevant context for a task"""
        # Retrieve related code
        code_context = self.retrieve_similar(
            f"code implementation for {task['description']}"
        )
        
        # Retrieve related tests
        test_context = self.retrieve_similar(
            f"tests for {task['description']}"
        )
        
        # Retrieve architecture decisions
        arch_context = self.retrieve_similar(
            f"architecture for {task['description']}"
        )
        
        return f"""
        Related Code:
        {chr(10).join(code_context[:2])}
        
        Related Tests:
        {chr(10).join(test_context[:2])}
        
        Architecture Context:
        {chr(10).join(arch_context[:1])}
        """
```

### 2.5 Tool Integration

```python
# tools/code_generator.py
import subprocess
from typing import Dict, Any
import os

class DotNetCodeGenerator:
    def __init__(self, project_path: str):
        self.project_path = project_path
        
    def create_project(self, name: str, project_type: str) -> bool:
        """Create new .NET project"""
        cmd = f"dotnet new {project_type} -n {name} -o {self.project_path}/{name}"
        result = subprocess.run(cmd, shell=True, capture_output=True)
        return result.returncode == 0
    
    def add_package(self, project: str, package: str) -> bool:
        """Add NuGet package"""
        cmd = f"dotnet add {self.project_path}/{project} package {package}"
        result = subprocess.run(cmd, shell=True, capture_output=True)
        return result.returncode == 0
    
    def generate_entity(self, spec: Dict[str, Any]) -> str:
        """Generate Entity Framework entity"""
        template = f"""
using System;
using System.ComponentModel.DataAnnotations;

namespace InfluenciAI.Domain.Entities
{{
    public class {spec['name']}
    {{
        [Key]
        public Guid Id {{ get; set; }} = Guid.NewGuid();
        
        {self._generate_properties(spec['properties'])}
        
        public DateTime CreatedAt {{ get; set; }} = DateTime.UtcNow;
        public DateTime UpdatedAt {{ get; set; }} = DateTime.UtcNow;
    }}
}}
"""
        return template
    
    def _generate_properties(self, properties: List[Dict]) -> str:
        prop_strings = []
        for prop in properties:
            data_type = self._map_type(prop['type'])
            required = "[Required]" if prop.get('required') else ""
            prop_strings.append(f"""
        {required}
        public {data_type} {prop['name']} {{ get; set; }}""")
        return "\n".join(prop_strings)
    
    def run_tests(self, project: str) -> Dict[str, Any]:
        """Run tests and return results"""
        cmd = f"dotnet test {self.project_path}/{project} --logger json"
        result = subprocess.run(cmd, shell=True, capture_output=True)
        
        return {
            "passed": result.returncode == 0,
            "output": result.stdout.decode(),
            "errors": result.stderr.decode()
        }
```

## 3. CONFIGURAÃ‡ÃƒO DO AMBIENTE DE DESENVOLVIMENTO

### 3.1 Docker Compose para Agentes

```yaml
# docker-compose.agents.yml
version: '3.8'

services:
  orchestrator:
    build:
      context: ./orchestration
      dockerfile: Dockerfile
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - AZURE_DEVOPS_TOKEN=${AZURE_DEVOPS_TOKEN}
    volumes:
      - ./project:/workspace
      - ./memory:/memory
    networks:
      - agent-network
      
  architect-agent:
    build:
      context: ./agents
      dockerfile: Dockerfile.architect
    environment:
      - AGENT_ROLE=architect
      - MODEL=gpt-4-turbo
    networks:
      - agent-network
      
  backend-agent:
    build:
      context: ./agents
      dockerfile: Dockerfile.backend
    environment:
      - AGENT_ROLE=backend
      - MODEL=gpt-4
    volumes:
      - ./project:/workspace
    networks:
      - agent-network
      
  qa-agent:
    build:
      context: ./agents
      dockerfile: Dockerfile.qa
    environment:
      - AGENT_ROLE=qa
      - MODEL=gpt-4
    volumes:
      - ./project:/workspace
    networks:
      - agent-network
      
  vector-db:
    image: chromadb/chroma:latest
    volumes:
      - chroma-data:/chroma/chroma
    networks:
      - agent-network
      
  redis:
    image: redis:alpine
    networks:
      - agent-network

networks:
  agent-network:
    driver: bridge

volumes:
  chroma-data:
```

### 3.2 VSCode Configuration for Agent Development

```json
// .vscode/settings.json
{
  "ai-agents.enabled": true,
  "ai-agents.config": {
    "orchestrator": {
      "endpoint": "http://localhost:8000",
      "timeout": 30000
    },
    "agents": [
      {
        "name": "architect",
        "trigger": "@architect",
        "capabilities": ["design", "review"]
      },
      {
        "name": "backend",
        "trigger": "@backend",
        "capabilities": ["code", "test", "refactor"]
      },
      {
        "name": "qa",
        "trigger": "@qa",
        "capabilities": ["test", "validate"]
      }
    ]
  },
  "ai-agents.shortcuts": {
    "ctrl+shift+a": "ai-agents.askArchitect",
    "ctrl+shift+b": "ai-agents.generateBackend",
    "ctrl+shift+t": "ai-agents.generateTests"
  }
}
```

## 4. MONITORAMENTO E OBSERVABILIDADE

### 4.1 Agent Performance Dashboard

```python
# monitoring/dashboard.py
from prometheus_client import Counter, Histogram, Gauge
import time

# Metrics
task_counter = Counter('agent_tasks_total', 'Total tasks processed', ['agent', 'task_type'])
task_duration = Histogram('agent_task_duration_seconds', 'Task processing duration', ['agent'])
active_agents = Gauge('active_agents', 'Number of active agents')
code_quality = Gauge('code_quality_score', 'Code quality score', ['component'])

class AgentMonitor:
    def __init__(self):
        self.metrics = {}
        
    def track_task(self, agent: str, task_type: str):
        task_counter.labels(agent=agent, task_type=task_type).inc()
        
    def track_duration(self, agent: str, duration: float):
        task_duration.labels(agent=agent).observe(duration)
        
    def update_quality(self, component: str, score: float):
        code_quality.labels(component=component).set(score)
    
    def generate_report(self) -> Dict:
        return {
            "total_tasks": sum(task_counter._metrics.values()),
            "avg_duration": {
                agent: self._calculate_avg_duration(agent)
                for agent in self.get_agents()
            },
            "quality_scores": {
                component: code_quality.labels(component=component)._value.get()
                for component in self.get_components()
            }
        }
```

## 5. MELHORES PRÃTICAS

### 5.1 Prompt Engineering para Agentes

```python
class PromptManager:
    def __init__(self):
        self.templates = self._load_templates()
        
    def get_system_prompt(self, agent_role: str) -> str:
        base_prompt = f"""
You are a {agent_role} working on the InfluenciAI platform.

Project Context:
- Multi-platform social media automation
- Tech Stack: .NET 8, Azure, PostgreSQL, Redis
- Architecture: Microservices, Event-Driven, CQRS
- Quality Standards: 80% test coverage, <100ms response time

Your Responsibilities:
{self.templates[agent_role]['responsibilities']}

Constraints:
{self.templates[agent_role]['constraints']}

Output Format:
{self.templates[agent_role]['output_format']}
"""
        return base_prompt
    
    def create_task_prompt(self, task: Dict, context: str) -> str:
        return f"""
Task: {task['description']}
Type: {task['type']}
Priority: {task['priority']}

Context from previous work:
{context}

Acceptance Criteria:
{task['acceptance_criteria']}

Please provide your solution:
"""
```

### 5.2 Error Handling and Recovery

```python
class AgentErrorHandler:
    def __init__(self):
        self.error_log = []
        self.recovery_strategies = {
            "timeout": self.handle_timeout,
            "invalid_output": self.handle_invalid_output,
            "api_error": self.handle_api_error
        }
    
    async def handle_error(self, error: Exception, agent: str, task: Dict):
        error_type = self.classify_error(error)
        recovery_strategy = self.recovery_strategies.get(error_type)
        
        if recovery_strategy:
            return await recovery_strategy(agent, task)
        else:
            # Escalate to orchestrator
            return await self.escalate(error, agent, task)
    
    async def handle_timeout(self, agent: str, task: Dict):
        # Retry with simpler task
        simplified_task = self.simplify_task(task)
        return await self.retry_with_timeout(agent, simplified_task, timeout=60)
    
    async def handle_invalid_output(self, agent: str, task: Dict):
        # Request clarification
        clarification = await self.request_clarification(agent, task)
        return await self.retry_with_clarification(agent, task, clarification)
```

## 6. CUSTOS E OTIMIZAÃ‡ÃƒO

### 6.1 Estimativa de Custos

| Componente | Uso Mensal | Custo UnitÃ¡rio | Custo Mensal |
|------------|------------|----------------|--------------|
| GPT-4 Turbo (Orchestrator) | 1M tokens | $0.01/1k | $10 |
| GPT-4 (Dev Agents) | 10M tokens | $0.03/1k | $300 |
| GPT-3.5 (QA/Doc) | 20M tokens | $0.001/1k | $20 |
| Vector DB | 10GB | $0.10/GB | $1 |
| Compute | 720 hours | $0.10/hour | $72 |
| **Total** | | | **$403/mÃªs** |

### 6.2 EstratÃ©gias de OtimizaÃ§Ã£o

```python
class CostOptimizer:
    def __init__(self):
        self.usage_tracker = {}
        self.cache = {}
        
    def optimize_model_selection(self, task: Dict) -> str:
        """Select appropriate model based on task complexity"""
        complexity = self.assess_complexity(task)
        
        if complexity == "simple":
            return "gpt-3.5-turbo"
        elif complexity == "medium":
            return "gpt-4"
        else:
            return "gpt-4-turbo"
    
    def use_cache_when_possible(self, query: str) -> Optional[str]:
        """Check cache before calling LLM"""
        cache_key = self.generate_cache_key(query)
        if cache_key in self.cache:
            return self.cache[cache_key]
        return None
    
    def batch_similar_tasks(self, tasks: List[Dict]) -> List[List[Dict]]:
        """Batch similar tasks to reduce API calls"""
        batches = {}
        for task in tasks:
            task_type = task['type']
            if task_type not in batches:
                batches[task_type] = []
            batches[task_type].append(task)
        
        return list(batches.values())
```
